{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Diffusion Policy for SO-101 Robot\n",
    "\n",
    "This notebook trains a **Diffusion Policy** on the SO-101 robot arm for pick-and-place tasks using [LeRobot](https://github.com/huggingface/lerobot).\n",
    "\n",
    "## What is Diffusion Policy?\n",
    "Diffusion Policy is a state-of-the-art imitation learning method that uses diffusion models to generate robot actions. It has shown excellent performance on manipulation tasks.\n",
    "\n",
    "## Dataset\n",
    "We use the official `lerobot/svla_so101_pickplace` dataset which contains 50 episodes (11,939 frames) of pick-and-place demonstrations on the SO-101 arm.\n",
    "\n",
    "## Requirements\n",
    "- Google Colab with GPU runtime (T4 or better)\n",
    "- Hugging Face account for uploading trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lerobot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Login to Hugging Face\n",
    "\n",
    "You'll need a Hugging Face account to upload your trained model. Get your token from https://huggingface.co/settings/tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set Environment Variables\n",
    "\n",
    "Replace `your_username` with your actual Hugging Face username."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Replace with your Hugging Face username\n",
    "HF_USER = \"your_username\"  # @param {type:\"string\"}\n",
    "\n",
    "os.environ[\"HF_USER\"] = HF_USER\n",
    "print(f\"Hugging Face user set to: {HF_USER}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Verify GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"WARNING: No GPU detected! Go to Runtime > Change runtime type > GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Diffusion Policy on SO-101 Pick-Place Dataset\n",
    "\n",
    "This will train a Diffusion Policy on the official SO-101 pick-place dataset.\n",
    "\n",
    "**Training parameters:**\n",
    "- `batch_size=32`: Reduced from 64 due to Colab memory limits\n",
    "- `steps=100000`: Good starting point for training\n",
    "- `eval_freq=10000`: Evaluate every 10k steps\n",
    "- `save_freq=10000`: Save checkpoint every 10k steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m lerobot.scripts.train \\\n",
    "    --policy.type=diffusion \\\n",
    "    --dataset.repo_id=lerobot/svla_so101_pickplace \\\n",
    "    --output_dir=outputs/train/diffusion_so101_pickplace \\\n",
    "    --job_name=diffusion_so101_pickplace \\\n",
    "    --policy.device=cuda \\\n",
    "    --batch_size=32 \\\n",
    "    --steps=100000 \\\n",
    "    --eval_freq=10000 \\\n",
    "    --save_freq=10000 \\\n",
    "    --wandb.enable=false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. (Optional) Train on Your Own Dataset\n",
    "\n",
    "If you have recorded your own SO-101 dataset, you can train on it instead.\n",
    "\n",
    "First, record a dataset following the [LeRobot data collection guide](https://github.com/huggingface/lerobot/blob/main/examples/7_get_started_with_real_robot.md), then run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and modify to train on your own dataset\n",
    "\n",
    "# CUSTOM_DATASET = f\"{HF_USER}/your_so101_dataset\"  # Replace with your dataset\n",
    "\n",
    "# !python -m lerobot.scripts.train \\\n",
    "#     --policy.type=diffusion \\\n",
    "#     --dataset.repo_id={CUSTOM_DATASET} \\\n",
    "#     --output_dir=outputs/train/diffusion_so101_custom \\\n",
    "#     --job_name=diffusion_so101_custom \\\n",
    "#     --policy.device=cuda \\\n",
    "#     --batch_size=32 \\\n",
    "#     --steps=100000 \\\n",
    "#     --eval_freq=10000 \\\n",
    "#     --save_freq=10000 \\\n",
    "#     --wandb.enable=false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Upload Trained Model to Hugging Face Hub\n",
    "\n",
    "After training completes, upload your model to share it or use it for inference on your robot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "HF_USER = os.environ.get(\"HF_USER\", \"your_username\")\n",
    "MODEL_NAME = \"diffusion_so101_pickplace\"\n",
    "CHECKPOINT_PATH = \"outputs/train/diffusion_so101_pickplace/checkpoints/last/pretrained_model\"\n",
    "\n",
    "print(f\"Uploading model to: {HF_USER}/{MODEL_NAME}\")\n",
    "!huggingface-cli upload {HF_USER}/{MODEL_NAME} {CHECKPOINT_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test Inference (Optional)\n",
    "\n",
    "You can test the trained policy with a quick inference check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lerobot.common.policies.diffusion.modeling_diffusion import DiffusionPolicy\n",
    "from lerobot.common.policies.diffusion.configuration_diffusion import DiffusionConfig\n",
    "import torch\n",
    "\n",
    "# Load the trained model\n",
    "checkpoint_path = \"outputs/train/diffusion_so101_pickplace/checkpoints/last/pretrained_model\"\n",
    "\n",
    "try:\n",
    "    policy = DiffusionPolicy.from_pretrained(checkpoint_path)\n",
    "    policy.eval()\n",
    "    print(\"Model loaded successfully!\")\n",
    "    print(f\"Policy config: {policy.config}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not load model: {e}\")\n",
    "    print(\"This is expected if training hasn't completed yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Deploy to your robot**: Download the model from Hugging Face Hub and run inference on your SO-101\n",
    "2. **Fine-tune**: If performance isn't satisfactory, collect more demonstrations and continue training\n",
    "3. **Compare policies**: Try training ACT or other policies on the same dataset to compare performance\n",
    "\n",
    "### Running inference on your robot:\n",
    "\n",
    "```python\n",
    "from lerobot.common.policies.diffusion.modeling_diffusion import DiffusionPolicy\n",
    "\n",
    "# Load from Hub\n",
    "policy = DiffusionPolicy.from_pretrained(\"your_username/diffusion_so101_pickplace\")\n",
    "policy.eval()\n",
    "\n",
    "# Run inference\n",
    "# ... (integrate with your robot control code)\n",
    "```\n",
    "\n",
    "## References\n",
    "\n",
    "- [LeRobot GitHub](https://github.com/huggingface/lerobot)\n",
    "- [Diffusion Policy Paper](https://arxiv.org/abs/2303.04137)\n",
    "- [SO-101 Pick-Place Dataset](https://huggingface.co/datasets/lerobot/svla_so101_pickplace)\n",
    "- [LeRobot Documentation](https://huggingface.co/docs/lerobot)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
