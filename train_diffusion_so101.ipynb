{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Train Diffusion Policy for SO-101 Robot\n\nThis notebook trains a **Diffusion Policy** on the SO-101 robot arm for pick-and-place tasks using [LeRobot](https://github.com/huggingface/lerobot).\n\n## What is Diffusion Policy?\nDiffusion Policy is a state-of-the-art imitation learning method that uses diffusion models to generate robot actions. It has shown excellent performance on manipulation tasks.\n\n## Dataset\nWe use the official `lerobot/svla_so101_pickplace` dataset which contains 50 episodes (11,939 frames) of pick-and-place demonstrations on the SO-101 arm with **dual cameras**:\n- `observation.images.up` — global/top-down view (480x640)\n- `observation.images.side` — side view (480x640)\n\nThe policy auto-adapts to the dataset's camera setup — both cameras will be used as visual inputs.\n\n## Requirements\n- Google Colab with GPU runtime (T4 or better)\n- Hugging Face account for uploading trained models"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "!pip install -U lerobot\n!pip install wandb  # optional, for logging\n\n# Reinstall torch+torchvision that match Colab's CUDA version\n# (lerobot can pull in an incompatible torchvision)\n!pip install torch torchvision --index-url https://download.pytorch.org/whl/cu124\n\n# Fix transformers <-> huggingface_hub version mismatch\n# (lerobot + torch reinstall can leave incompatible versions)\n!pip install -U transformers huggingface_hub"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Login to Hugging Face\n\nUses your Colab secrets `HF_USER` and `HF_TOKEN` (set in the key icon in the left sidebar)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nfrom google.colab import userdata\n\nHF_USER = userdata.get('HF_USER')\nHF_TOKEN = userdata.get('HF_TOKEN')\n\nos.environ[\"HF_USER\"] = HF_USER\nos.environ[\"HF_TOKEN\"] = HF_TOKEN\n\n# Login to Hugging Face CLI\n!huggingface-cli login --token {HF_TOKEN}\n\nprint(f\"Logged in as: {HF_USER}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Verify GPU Availability"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"WARNING: No GPU detected! Go to Runtime > Change runtime type > GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Explore the Dataset\n\nLet's inspect the dataset to confirm the camera setup and data shape before training."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from lerobot.datasets.lerobot_dataset import LeRobotDataset\n\ndataset = LeRobotDataset(\"lerobot/svla_so101_pickplace\")\nprint(f\"Number of episodes: {dataset.num_episodes}\")\nprint(f\"Number of frames: {dataset.num_frames}\")\nprint(f\"FPS: {dataset.fps}\")\nprint(f\"\\nFeatures:\")\nfor key, feat in dataset.features.items():\n    print(f\"  {key}: {feat}\")\n\n# Show a sample frame\nsample = dataset[0]\nprint(f\"\\nSample keys: {list(sample.keys())}\")\nfor k, v in sample.items():\n    if hasattr(v, 'shape'):\n        print(f\"  {k}: shape={v.shape}, dtype={v.dtype}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Test Run (100 steps)\n\nQuick sanity check to make sure everything works before committing to a full training run."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Short test run — 100 steps, batch_size=8 (safe for T4 16GB)\n!python -m lerobot.scripts.lerobot_train \\\n    --policy.type=diffusion \\\n    --dataset.repo_id=lerobot/svla_so101_pickplace \\\n    --output_dir=outputs/train/diffusion_so101_test \\\n    --job_name=diffusion_so101_test \\\n    --policy.device=cuda \\\n    --policy.push_to_hub=false \\\n    --batch_size=8 \\\n    --steps=100 \\\n    --save_freq=50 \\\n    --log_freq=10 \\\n    --wandb.enable=false"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. Full Training Run\n\nOnce the test run completes successfully, run the full training. Adjust `steps` and `batch_size` based on your Colab GPU.\n\n| GPU | Recommended batch_size | ~Time for 100k steps |\n|-----|----------------------|---------------------|\n| T4 (16GB) | 8 | ~8-10 hours |\n| A100 (40GB) | 32 | ~2-3 hours |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "!python -m lerobot.scripts.lerobot_train \\\n    --policy.type=diffusion \\\n    --dataset.repo_id=lerobot/svla_so101_pickplace \\\n    --output_dir=outputs/train/diffusion_so101_pickplace \\\n    --job_name=diffusion_so101_pickplace \\\n    --policy.device=cuda \\\n    --policy.push_to_hub=false \\\n    --batch_size=8 \\\n    --steps=100000 \\\n    --save_freq=10000 \\\n    --log_freq=100 \\\n    --wandb.enable=false"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. (Optional) Train on Your Own Dataset\n\nIf you have recorded your own SO-101 dataset with wrist + global cameras, train on it instead. The policy will auto-detect your camera names from the dataset."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Uncomment and modify to train on your own dataset\n# Your dataset should have camera keys like:\n#   observation.images.wrist  (wrist-mounted camera)\n#   observation.images.top    (global/top-down camera)\n# The policy will auto-adapt to whatever camera names your dataset uses.\n\n# CUSTOM_DATASET = f\"{HF_USER}/your_so101_dataset\"\n\n# !python -m lerobot.scripts.lerobot_train \\\n#     --policy.type=diffusion \\\n#     --dataset.repo_id={CUSTOM_DATASET} \\\n#     --output_dir=outputs/train/diffusion_so101_custom \\\n#     --job_name=diffusion_so101_custom \\\n#     --policy.device=cuda \\\n#     --policy.push_to_hub=false \\\n#     --batch_size=8 \\\n#     --steps=100000 \\\n#     --save_freq=10000 \\\n#     --log_freq=100 \\\n#     --wandb.enable=false"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8. Upload Trained Model to Hugging Face Hub\n\nAfter training completes, upload your model to share it or use it for inference on your robot."
  },
  {
   "cell_type": "code",
   "source": "MODEL_NAME = \"diffusion_so101_pickplace\"\nCHECKPOINT_PATH = \"outputs/train/diffusion_so101_pickplace/checkpoints/last/pretrained_model\"\n\nprint(f\"Uploading model to: {HF_USER}/{MODEL_NAME}\")\n!huggingface-cli upload {HF_USER}/{MODEL_NAME} {CHECKPOINT_PATH}",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 9. Test Inference (Optional)\n\nQuick check that the trained model loads correctly.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from lerobot.policies.diffusion.modeling_diffusion import DiffusionPolicy\nimport torch\n\ncheckpoint_path = \"outputs/train/diffusion_so101_pickplace/checkpoints/last/pretrained_model\"\n\ntry:\n    policy = DiffusionPolicy.from_pretrained(checkpoint_path)\n    policy.eval()\n    print(\"Model loaded successfully!\")\n    print(f\"Input features: {policy.config.input_features}\")\n    print(f\"Output features: {policy.config.output_features}\")\nexcept Exception as e:\n    print(f\"Could not load model: {e}\")\n    print(\"This is expected if training hasn't completed yet.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## References\n\n- [LeRobot GitHub](https://github.com/huggingface/lerobot)\n- [Diffusion Policy Paper](https://arxiv.org/abs/2303.04137)\n- [SO-101 Pick-Place Dataset](https://huggingface.co/datasets/lerobot/svla_so101_pickplace)\n- [LeRobot Colab Notebooks](https://huggingface.co/docs/lerobot/notebooks)\n- [LeRobot Docs — Training on Real Robots](https://huggingface.co/docs/lerobot/en/il_robots)",
   "metadata": {}
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}